{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f273c8d4-40fb-474e-8ba3-01281c691081",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Step 1: Verify the Flatten Logic\n",
    "Build and validate the logic in Python before converting to Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aaec11c3-24a8-432e-981a-c427d12fb472",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "with open('negotiated_rates.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Preview the top-level keys\n",
    "print('Top-level keys:', list(data.keys()))\n",
    "print('Number of out_of_network entries:', len(data['out_of_network']))\n",
    "print()\n",
    "\n",
    "# Preview one entry to understand the structure\n",
    "print(json.dumps(data['out_of_network'][0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93a16b5d-981f-449f-9801-5d564e2e0537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Flatten the nested JSON into a list of dictionaries\n",
    "\n",
    "#   1. Each item in out_of_network\n",
    "#   2. Each item in allowed_amounts (different service_code / provider groups)\n",
    "#   3. Each provider in payments.providers, and each npi within that provider\n",
    "\n",
    "flat_rows = []\n",
    "\n",
    "for procedure in data['out_of_network']:\n",
    "    # Pull the procedure-level fields\n",
    "    name            = procedure['name']\n",
    "    billing_code_type = procedure['billing_code_type']\n",
    "    billing_code    = procedure['billing_code']\n",
    "    description     = procedure['description']\n",
    "\n",
    "    # Explode level 1: each allowed_amount entry\n",
    "    for amount in procedure['allowed_amounts']:\n",
    "        service_code    = amount['service_code']\n",
    "        billing_class   = amount['billing_class']\n",
    "        allowed_amount  = amount['payments']['allowed_amount']\n",
    "\n",
    "        # Explode level 2: each provider within this amount\n",
    "        for provider in amount['payments']['providers']:\n",
    "            billed_charge = provider['billed_charge']\n",
    "\n",
    "            # Explode level 3: each NPI in the provider's npi list\n",
    "            for npi in provider['npi']:\n",
    "                flat_rows.append({\n",
    "                    'name':              name,\n",
    "                    'billing_code_type': billing_code_type,\n",
    "                    'billing_code':      billing_code,\n",
    "                    'description':       description,\n",
    "                    'service_code':      service_code,\n",
    "                    'billing_class':     billing_class,\n",
    "                    'allowed_amount':    allowed_amount,\n",
    "                    'billed_charge':     billed_charge,\n",
    "                    'npi':               int(npi)   # Cast to int to drop the .0\n",
    "                })\n",
    "\n",
    "print(f'Total flattened rows: {len(flat_rows)}')\n",
    "print()\n",
    "\n",
    "# Display all rows for verification\n",
    "for i, row in enumerate(flat_rows):\n",
    "    print(f'--- Row {i} ---')\n",
    "    for k, v in row.items():\n",
    "        print(f'  {k:20s} {v}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ead907fc-3e87-4a9f-b69d-234654c3b402",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Step 2: Convert to Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d85f8c12-97f6-4b54-b673-aa1806951017",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "# Step 2a: Read JSON - use multiline=True since this is a single JSON object\n",
    "df = spark.read.option(\"multiLine\", \"true\").json('/Workspace/Users/jay.kline21@outlook.com/data-5035-2026/week03/negotiated_rates.json')\n",
    "\n",
    "# Look at the schema that Spark inferred\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "588de136-4a88-46c7-a8c8-195acd94e0d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 2b: Explode out_of_network list into one row per procedure\n",
    "df_procedures = df_raw.select(\n",
    "    explode(col('out_of_network')).alias('procedure')\n",
    ")\n",
    "\n",
    "df_procedures.printSchema()\n",
    "df_procedures.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d4a3aa0-0744-4b97-b0bc-3c647792e3be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 2c: Pull procedure-level fields and explode allowed_amounts\n",
    "df_amounts = df_procedures.select(\n",
    "    col('procedure.name').alias('name'),\n",
    "    col('procedure.billing_code_type').alias('billing_code_type'),\n",
    "    col('procedure.billing_code').alias('billing_code'),\n",
    "    col('procedure.description').alias('description'),\n",
    "    explode(col('procedure.allowed_amounts')).alias('amount')\n",
    ")\n",
    "\n",
    "df_amounts.printSchema()\n",
    "df_amounts.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fda28c3-293a-43f9-a7f0-e987c8972e19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 2d: Pull amount-level fields and explode providers\n",
    "df_providers = df_amounts.select(\n",
    "    col('name'),\n",
    "    col('billing_code_type'),\n",
    "    col('billing_code'),\n",
    "    col('description'),\n",
    "    col('amount.service_code').alias('service_code'),\n",
    "    col('amount.billing_class').alias('billing_class'),\n",
    "    col('amount.payments.allowed_amount').alias('allowed_amount'),\n",
    "    explode(col('amount.payments.providers')).alias('provider')\n",
    ")\n",
    "\n",
    "df_providers.printSchema()\n",
    "df_providers.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "367825b8-1919-449e-8268-3b66a1961e4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 2e: Pull provider-level fields and explode npi list\n",
    "df_npis = df_providers.select(\n",
    "    col('name'),\n",
    "    col('billing_code_type'),\n",
    "    col('billing_code'),\n",
    "    col('description'),\n",
    "    col('service_code'),\n",
    "    col('billing_class'),\n",
    "    col('allowed_amount'),\n",
    "    col('provider.billed_charge').alias('billed_charge'),\n",
    "    explode(col('provider.npi')).alias('npi')\n",
    ")\n",
    "\n",
    "df_npis.printSchema()\n",
    "df_npis.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27d8f78e-8b3f-489a-8b85-3a7ba1f42d7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Step 2f: Cast NPI\n",
    "df_final = df_npis.withColumn('npi', col('npi').cast('long'))\n",
    "\n",
    "# Display the final table\n",
    "df_final.show(truncate=False)\n",
    "\n",
    "print(f'Total rows: {df_final.count()}')\n",
    "df_final.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ebe3dc5-cff6-4ff3-83c7-5efdc9638a48",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build a Spark DataFrame from the Python list\n",
    "df_python = spark.createDataFrame(flat_rows)\n",
    "\n",
    "print('Python row count: ', df_python.count())\n",
    "print('Spark  row count: ', df_final.count())\n",
    "print()\n",
    "\n",
    "# Sort both by the same columns so ordering is deterministic, then compare\n",
    "sort_cols = ['billing_code', 'service_code', 'npi']\n",
    "\n",
    "df_python_sorted = df_python.orderBy(sort_cols)\n",
    "df_spark_sorted  = df_final.orderBy(sort_cols)\n",
    "\n",
    "print('--- Python Output ---')\n",
    "df_python_sorted.show(truncate=False)\n",
    "\n",
    "print('--- Spark Output ---')\n",
    "df_spark_sorted.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0bd0635-0e76-4cd7-be83-ed6c02522031",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Just call display() on your final dataframe\n",
    "display(df_final)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "exercise03",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
